# Kamaji Local Setup - Complete Guide

Multi-tenant Kubernetes using [Kamaji](https://kamaji.clastix.io/) with worker nodes for running actual workloads.

**Time to complete:** 20-25 minutes

---

## ğŸ“‹ Prerequisites

```bash
# Check you have these installed:
docker --version      # Need 20.10+
kind --version        # Need 0.20.0+
helm version          # Need 3.12.0+
kubectl version       # Need 1.28.0+
vagrant --version     # Need 2.2.0+ (for worker nodes)
```

**Missing tools?** See [docs/PREREQUISITES.md](docs/PREREQUISITES.md)

---

## ğŸš€ Quick Setup

### Option 1: Full Setup (Recommended)

```bash
# Install worker node prerequisites first
sudo apt-get install vagrant libvirt-dev qemu-kvm libvirt-daemon-system libvirt-clients bridge-utils
vagrant plugin install vagrant-libvirt
sudo systemctl start libvirtd

# Fix file limits (prevents "too many open files" error)
sudo sysctl fs.inotify.max_user_instances=512
sudo sysctl fs.inotify.max_user_watches=524288

# Run complete setup (everything automated)
./scripts/setup.sh
```

**Takes:** 20-25 minutes  
**Creates:**
- kind cluster with Kamaji
- 3 tenant control planes (tcp-dev, tcp-staging, tcp-prod)
- Kubeconfigs extracted automatically
- 3 worker VMs joined to control planes

### Option 2: Skip Worker Nodes

```bash
# Setup without worker VMs (control planes only)
./scripts/setup.sh --skip-workers
```

**Takes:** 10-15 minutes  
**Note:** You can add workers later using [WORKER-SETUP.md](WORKER-SETUP.md)

---

## âœ… Verify Installation

```bash
# Check nodes are Ready
for env in dev staging prod; do
  echo "=== tcp-${env} ==="
  kubectl --kubeconfig=scripts/kubeconfigs/tcp-${env}.kubeconfig get nodes
  echo ""
done
```

**Expected:** Each cluster shows one worker node in "Ready" state

---

## ğŸ¯ Deploy Demo Apps

```bash
# Deploy nginx to all environments
kubectl --kubeconfig=scripts/kubeconfigs/tcp-dev.kubeconfig apply -f manifests/examples/nginx-dev.yaml
kubectl --kubeconfig=scripts/kubeconfigs/tcp-staging.kubeconfig apply -f manifests/examples/nginx-staging.yaml
kubectl --kubeconfig=scripts/kubeconfigs/tcp-prod.kubeconfig apply -f manifests/examples/nginx-prod.yaml

# Wait for pods to run
kubectl --kubeconfig=scripts/kubeconfigs/tcp-dev.kubeconfig get pods -n demo -w
# Press Ctrl+C when Running

# Get LoadBalancer IPs
for env in dev staging prod; do
  echo "=== tcp-${env} ==="
  kubectl --kubeconfig=scripts/kubeconfigs/tcp-${env}.kubeconfig get svc -n demo
  echo ""
done
```

## ğŸŒ Access Applications

```bash
# Use the EXTERNAL-IP from step 6
curl http://<EXTERNAL-IP>

# Or open in browser: http://<EXTERNAL-IP>
```

**Expected:**
- Dev: Purple page "DEVELOPMENT Environment"
- Staging: Pink page "STAGING Environment"
- Prod: Blue page "PRODUCTION Environment"

---

## ğŸ§¹ Cleanup

```bash
# Remove everything (kind cluster + VMs)
./scripts/99-cleanup.sh

# Or remove only worker VMs (keep control planes)
./scripts/08-cleanup-workers.sh
```

---

## ğŸ“š Additional Info

### Architecture

```
Host Machine
â”œâ”€â”€ kind Cluster (Management - Docker)
â”‚   â”œâ”€â”€ Kamaji Operator
â”‚   â”œâ”€â”€ cert-manager
â”‚   â”œâ”€â”€ MetalLB
â”‚   â””â”€â”€ Tenant Control Planes (pods)
â”‚       â”œâ”€â”€ tcp-dev (API, etcd, scheduler, controller)
â”‚       â”œâ”€â”€ tcp-staging
â”‚       â””â”€â”€ tcp-prod
â””â”€â”€ Worker VMs (libvirt/KVM)
    â”œâ”€â”€ tcp-dev-worker â†’ joins tcp-dev
    â”œâ”€â”€ tcp-staging-worker â†’ joins tcp-staging
    â””â”€â”€ tcp-prod-worker â†’ joins tcp-prod
```

### What You Get

- âœ… 3 isolated tenant Kubernetes clusters
- âœ… Each with dedicated control plane (API server, etcd, scheduler)
- âœ… Each with one worker node (VM) for running pods
- âœ… LoadBalancer IPs for services
- âœ… Demo nginx apps showing environment isolation
- âœ… Full kubectl access to each tenant

### Common Commands

```bash
# View all tenant control planes
kubectl get tenantcontrolplanes

# Check control plane pods
kubectl get pods -l 'kamaji.clastix.io/component=control-plane'

# View LoadBalancer IPs
kubectl get svc -l 'kamaji.clastix.io/name'

# SSH into a worker VM
vagrant ssh tcp-dev-worker

# Check kubelet on worker
vagrant ssh tcp-dev-worker -c "sudo systemctl status kubelet"
```

---

## ğŸ”§ Troubleshooting

**Full guide:** [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) | [WORKER-SETUP.md](WORKER-SETUP.md)

**Quick fixes:**

```bash
# Pods stuck Pending? Workers not joined yet
for tenant in dev staging prod; do ./scripts/join-worker.sh ${tenant}; done

# "Too many open files"?
sudo sysctl fs.inotify.max_user_instances=512
sudo sysctl fs.inotify.max_user_watches=524288
sudo systemctl restart libvirtd

# Check logs
kubectl logs -n kamaji-system -l control-plane=controller-manager --tail=50
vagrant ssh tcp-dev-worker -c "sudo journalctl -u kubelet -n 50"
```

---

## ğŸ“– References

- [Kamaji Documentation](https://kamaji.clastix.io/)
- [Kamaji GitHub](https://github.com/clastix/kamaji)
- [kind Documentation](https://kind.sigs.k8s.io/)
- [Vagrant Documentation](https://www.vagrantup.com/docs)
